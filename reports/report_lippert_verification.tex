%\subtask{Describe and discuss your ``objective method'', ie. the method by which you will measure the success of your predictor.}

The functionality of the system will be verified by doing regular predictions and comparing these to the actual 
parking situation later. Similar to the crawling implementation, the web application will generate a new prediction 
``15 minutes into the future''. These predictions will be saved in a database. 

To measure the error, we will use the mean absolute error 
\[
MAE \defeq mean(|y_i^∗ − y_i|)\text{.}
\]

The evaluations were fetched on 2017-03-11 at 6pm. Tables \ref{tab:eval_doy} and \ref{tab:eval_woy} list the \(MAE\)

\input{tab_eval_doy}
\input{tab_eval_woy}
\input{fig_actual}
\input{fig_predictions}

TODO\todo{what do these numbers mean?}\todo{how did we achieve them?}

\todo{how do we verify?}
\todo{what method do we use to measure error?}
\todo{verification over time?}
\todo{implementation}

At the moment, the predictions are of very bad quality and not usable. For 403 predictions, the average absolute error had a mean of \(144.14\) with a standard deviation of \(99.68\).

In rare cases, the predictions are quite good. \(47\) predictions were off by less than \(20\), 
\(19\) predictions were off by less than \(10\), and \(6\) predictions were off by less than 2. One goal -- beside improving the prediction accuracy overall -- will be to understand why these predictions were so good.

The original predictions were achieved by training a RegressionTree on tuples of the form 
\[
((\hod, \moh, \dow, \dom, \wom, \woy, \yyy), free)\text{.}
\]
Since these results are very unsatisfactory, other methods will be investigated until the final report.